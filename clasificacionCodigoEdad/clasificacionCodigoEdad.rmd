```{r}
# Install and load the lubridate package if not already installed
if (!requireNamespace("lubridate", quietly = TRUE)) {
  install.packages("lubridate")
}
library(lubridate)

# Install and load the xgboost package if not already installed
if (!requireNamespace("xgboost", quietly = TRUE)) {
  install.packages("xgboost")
}
library(xgboost)

# Install and load the lightgbm package if not already installed
if (!requireNamespace("lightgbm", quietly = TRUE)) {
  install.packages("lightgbm")
}
library(lightgbm)

# Install and load the data.table package if not already installed
if (!requireNamespace("data.table", quietly = TRUE)) {
  install.packages("data.table")
}
library(data.table)

# Install and load the dplyr package if not already installed
if (!requireNamespace("dplyr", quietly = TRUE)) {
  install.packages("dplyr")
}
library(dplyr)

# Install and load the caret package if not already installed
if (!requireNamespace("caret", quietly = TRUE)) {
  install.packages("caret")
}
library(caret)
```

# Step 1: Data Preprocessing

```{r}
# Load dataset
anillamientos <- read.csv("../limpieza/limpio/anillamiento_familia.csv")
```


```{r}
anillamientos_especie <- anillamientos[, (names(anillamientos) %in% c("NombreEspecie", "FechaCaptura", "CodigoEdad", "MUNICIPIO", "CodigoSexo"))]
anillamientos_familia <- anillamientos[, (names(anillamientos) %in% c("Familia", "FechaCaptura", "CodigoEdad", "MUNICIPIO", "CodigoSexo"))]
anillamientos_orden <- anillamientos[, (names(anillamientos) %in% c("Orden", "FechaCaptura", "CodigoEdad", "MUNICIPIO", "CodigoSexo"))]
anillamientos_grupo <- anillamientos[, (names(anillamientos) %in% c("Grupo", "FechaCaptura", "CodigoEdad", "MUNICIPIO", "CodigoSexo"))]
anillamientos_anilla <- anillamientos[, (names(anillamientos) %in% c("Anilla", "FechaCaptura", "CodigoEdad", "CodigoLocalidad", "CodigoSexo"))]
```

```{r}
dataset_trabajo <- anillamientos_anilla #A modificar para lo que busquemos
names(dataset_trabajo)[1] <- "Identificador"
dataset_trabajo$FechaCaptura <- as.Date(dataset_trabajo$FechaCaptura)
dataset_trabajo$MesCaptura <- month(dataset_trabajo$FechaCaptura)
dataset_trabajo <- dataset_trabajo[, (!names(dataset_trabajo) %in% c("FechaCaptura"))]
dataset_trabajo <- dataset_trabajo[dataset_trabajo$CodigoLocalidad != "", ]
dataset_trabajo$CodigoEdad <- as.numeric(dataset_trabajo$CodigoEdad)
dataset_trabajo <- dataset_trabajo[dataset_trabajo$CodigoEdad <= 9, ]
dataset_trabajo$Identificador <- as.integer(as.factor(dataset_trabajo$Identificador))
dataset_trabajo$CodigoLocalidad <- as.integer(as.factor(dataset_trabajo$CodigoLocalidad))
dataset_trabajo$CodigoSexo <- as.integer(as.factor(dataset_trabajo$CodigoSexo))
```

```{r}
dataset_trabajo <- na.omit(dataset_trabajo)
```

```{r}
set.seed(123)

train_index <- sample(1:nrow(dataset_trabajo), 0.7 * nrow(dataset_trabajo))
train_data <- dataset_trabajo[train_index, ]
test_data <- dataset_trabajo[-train_index, ]
```


# Step 2: Model Training

# Train a xgb models

```{r}
start_time <- Sys.time()
xgb_model_1 <- xgboost(data = as.matrix(train_data[, c("Identificador", "CodigoLocalidad", "MesCaptura", "CodigoSexo")]),
                     label = train_data$CodigoEdad,
                     nrounds = 1,
                     verbose = FALSE,
                     objective = "multi:softmax",
                     num_class = 10
)
end_time <- Sys.time()
elapsed_time <- end_time - start_time
print(elapsed_time)
```

```{r}
start_time <- Sys.time()
xgb_model_50 <- xgboost(data = as.matrix(train_data[, c("Identificador", "CodigoLocalidad", "MesCaptura", "CodigoSexo")]),
                     label = train_data$CodigoEdad,
                     nrounds = 50,
                     verbose = FALSE,
                     objective = "multi:softmax",
                     num_class = 10
)
end_time <- Sys.time()
elapsed_time <- end_time - start_time
print(elapsed_time)
```

```{r}
start_time <- Sys.time()
xgb_model_100 <- xgboost(data = as.matrix(train_data[, c("Identificador", "CodigoLocalidad", "MesCaptura", "CodigoSexo")]),
                     label = train_data$CodigoEdad,
                     nrounds = 100,
                     verbose = FALSE,
                     objective = "multi:softmax",
                     num_class = 10
)
end_time <- Sys.time()
elapsed_time <- end_time - start_time
print(elapsed_time)
```

```{r}
start_time <- Sys.time()
xgb_model_200 <- xgboost(data = as.matrix(train_data[, c("Identificador", "CodigoLocalidad", "MesCaptura", "CodigoSexo")]),
                     label = train_data$CodigoEdad,
                     nrounds = 200,
                     verbose = FALSE,
                     objective = "multi:softmax",
                     num_class = 10
)
end_time <- Sys.time()
elapsed_time <- end_time - start_time
print(elapsed_time)
```

# Train a lightgbm models

```{r}
target <- "CodigoEdad"
categorical_features <- c("Identificador", "CodigoLocalidad", "MesCaptura", "CodigoSexo")

train <- lgb.Dataset(data = as.matrix(train_data[, c("Identificador", "CodigoLocalidad", "MesCaptura", "CodigoSexo")]),
                     label = as.numeric(train_data[[target]]),
                     categorical_feature = categorical_features)

params <- list(objective = "multiclass",
               num_class = 10,
               metric = "multi_logloss")
```

```{r}
start_time <- Sys.time()
lightgbm_model_1 <- lgb.train(params = params,
                                data = train,
                                nrounds = 1,
                                verbose = 0)
end_time <- Sys.time()
elapsed_time <- end_time - start_time
print(elapsed_time)
```

```{r}
start_time <- Sys.time()
lightgbm_model_50 <- lgb.train(params = params,
                                data = train,
                                nrounds = 50,
                                verbose = 0)
end_time <- Sys.time()
elapsed_time <- end_time - start_time
print(elapsed_time)
```

```{r}
start_time <- Sys.time()
lightgbm_model_100 <- lgb.train(params = params,
                                data = train,
                                nrounds = 100,
                                verbose = 0)
end_time <- Sys.time()
elapsed_time <- end_time - start_time
print(elapsed_time)
```

```{r}
start_time <- Sys.time()
lightgbm_model_200 <- lgb.train(params = params,
                                data = train,
                                nrounds = 200,
                                verbose = 0)
end_time <- Sys.time()
elapsed_time <- end_time - start_time
print(elapsed_time)
```

# Step 3: Model Evaluation

# Predict on the testing set and evaluate
```{r}
predictions_xgb_1 <- predict(xgb_model_1, as.matrix(test_data[, c("Identificador", "CodigoLocalidad", "MesCaptura", "CodigoSexo")]))
conf_matrix_xgb_1 <- table(predictions_xgb_1, test_data$CodigoEdad)
accuracy_xgb_1 <- sum(diag(conf_matrix_xgb_1)) / sum(conf_matrix_xgb_1)
print(paste("Accuracy 1 rounds:", accuracy_xgb_1))
```

```{r}
predictions_xgb_50 <- predict(xgb_model_50, as.matrix(test_data[, c("Identificador", "CodigoLocalidad", "MesCaptura", "CodigoSexo")]))
conf_matrix_xgb_50 <- table(predictions_xgb_50, test_data$CodigoEdad)
accuracy_xgb_50 <- sum(diag(conf_matrix_xgb_50)) / sum(conf_matrix_xgb_50)
print(paste("Accuracy 50 rounds:", accuracy_xgb_50))
```

```{r}
predictions_xgb_100 <- predict(xgb_model_100, as.matrix(test_data[, c("Identificador", "CodigoLocalidad", "MesCaptura", "CodigoSexo")]))
conf_matrix_xgb_100 <- table(predictions_xgb_100, test_data$CodigoEdad)
accuracy_xgb_100 <- sum(diag(conf_matrix_xgb_100)) / sum(conf_matrix_xgb_100)
print(paste("Accuracy 100 rounds:", accuracy_xgb_100))
```

```{r}
predictions_xgb_200 <- predict(xgb_model_200, as.matrix(test_data[, c("Identificador", "CodigoLocalidad", "MesCaptura", "CodigoSexo")]))
conf_matrix_xgb_200 <- table(predictions_xgb_200, test_data$CodigoEdad)
accuracy_xgb_200 <- sum(diag(conf_matrix_xgb_200)) / sum(conf_matrix_xgb_200)
print(paste("Accuracy 200 rounds:", accuracy_xgb_200))
```
## The accuracy obtained is lower than the obtained when done with all attributes, but the time invested is aproximately 1/4th

```{r}
predictions_lightgbm_1 <- predict(lightgbm_model_1, as.matrix(test_data[, c("Identificador", "CodigoLocalidad", "MesCaptura", "CodigoSexo")]))
predicted_labels <- as.factor(apply(predictions_lightgbm_1, 1, which.max))
conf_matrix_lightgbm_1 <- table(predicted_labels, test_data$CodigoEdad)
accuracy_lightgbm_1 <- sum(diag(conf_matrix_lightgbm_1)) / sum(conf_matrix_lightgbm_1)
print(paste("Accuracy 1 rounds:", accuracy_lightgbm_1))
```

```{r}
predictions_lightgbm_50 <- predict(lightgbm_model_50, as.matrix(test_data[, c("Identificador", "CodigoLocalidad", "MesCaptura", "CodigoSexo")]))
predicted_labels <- as.factor(apply(predictions_lightgbm_50, 1, which.max))
conf_matrix_lightgbm_50 <- table(predicted_labels, test_data$CodigoEdad)
accuracy_lightgbm_50 <- sum(diag(conf_matrix_lightgbm_50)) / sum(conf_matrix_lightgbm_50)
print(paste("Accuracy 50 rounds:", accuracy_lightgbm_50))
```

```{r}
predictions_lightgbm_100 <- predict(lightgbm_model_100, as.matrix(test_data[, c("Identificador", "CodigoLocalidad", "MesCaptura", "CodigoSexo")]))
predicted_labels <- as.factor(apply(predictions_lightgbm_100, 1, which.max))
conf_matrix_lightgbm_100 <- table(predicted_labels, test_data$CodigoEdad)
accuracy_lightgbm_100 <- sum(diag(conf_matrix_lightgbm_100)) / sum(conf_matrix_lightgbm_100)
print(paste("Accuracy 100 rounds:", accuracy_lightgbm_100))
```

```{r}
predictions_lightgbm_200 <- predict(lightgbm_model_200, as.matrix(test_data[, c("Identificador", "CodigoLocalidad", "MesCaptura", "CodigoSexo")]))
predicted_labels <- as.factor(apply(predictions_lightgbm_200, 1, which.max))
conf_matrix_lightgbm_200 <- table(predicted_labels, test_data$CodigoEdad)
accuracy_lightgbm_200 <- sum(diag(conf_matrix_lightgbm_200)) / sum(conf_matrix_lightgbm_200)
print(paste("Accuracy 200 rounds:", accuracy_lightgbm_200))
```

# Cross-Validation xgboost

```{r}
# Define data and parameters
dtrain <- xgb.DMatrix(as.matrix(train_data[, c("Identificador", "CodigoLocalidad", "MesCaptura", "CodigoSexo")]), label = train_data$CodigoEdad)
params <- list(
  objective = "multi:softmax",
  num_class = 10
)

# Perform cross-validation
cv <- xgb.cv(data = dtrain,
             params = params,
             nrounds = 100,
             nfold = 5, # Number of folds for cross-validation
             metrics = "merror", # Evaluation metric: classification error
             verbose = TRUE
)

# Plot the accuracy
plot(cv$evaluation_log$iter, 1 - cv$evaluation_log$test_merror_mean, type = "l", 
     xlab = "Número de rondas", ylab = "Precisión")
```

